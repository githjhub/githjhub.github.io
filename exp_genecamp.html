<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project 1 - DEGs vs AI</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 40px auto;
      padding: 0 20px;
      line-height: 1.6;
      color: #333;
    }
    img {
      width: auto;
      max-height: 400px;
      object-fit: auto;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    h1 {
      font-size: 1.8em;
      margin-bottom: 10px;
    }
    p.description {
      font-size: 0.95em;
      color: #555;
    }
  </style>
</head>
<body>

  <img src="bk.JPG" alt="Project Banner">

  <h1>Optimization of preprocessing strategies for developing AI-based disease diagnosis model using whole transcriptomic data</h1>

  <p class="description">
    Current research in medicine and biology predominantly focuses on applying artificial intelligence (AI) to analyze patient-specific imaging data, such as CT and MRI scans. However, the application of AI to next-generation sequencing (NGS) data, particularly transcriptomics, remains underutilized. RNA sequencing data is prone to biological and technical variability during generation, and the choice of error-correction and preprocessing methods can significantly influence downstream analyses. These challenges underscore the need for clear and systematic guidelines to optimize transcriptome data for AI-based analyses. In this study, we aim to identify optimal preprocessing strategies for developing AI models leveraging transcriptomic data. We utilized RNA sequencing datasets from 25 independent cohorts, comprising over 5,800 patients with conditions such as lung adenocarcinoma, colorectal cancer, diabetes, and other diseases. A total of 18 combinatorial preprocessing pipelines were systematically assessed, encompassing 6 normalization methods (Raw, CPMTMM, RLE, UQ, RPKM, TPM) and 3 scaling methods (None, MinMax, Z-score). Over 20,000 transcripts were processed using each combination of normalization and scaling techniques. We then developed disease diagnosis models using 13 machine learning and deep learning algorithms. The performance of these models was evaluated to identify the most effective preprocessing strategies for transcriptomic data. We identified algorithm-specific optimal preprocessing strategies to develop robust AI models utilizing transcriptomic data. Performance variations driven by normalization and scaling methods were observed for each algorithm, with these differences being particularly pronounced in datasets characterized by inherently lower model performance (difficult tasks). Our findings underscore the critical role of preprocessing in shaping model outcomes and provide a foundation for the development of tailored AI frameworks for disease diagnosis. This study offers a systematic approach to optimize transcriptomics-based predictive modeling, advancing the integration of AI into transcriptomic data analysis for clinical applications.   </p>

</body>
</html>